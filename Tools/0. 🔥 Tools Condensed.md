^Top
## Table of Contents
- [Python](#Python)
	- [Unit-testing](#Unit-testing)
		- [Pytest](#Pytest)
	- [Static-type-checking](#Static-type-checking)
		- [Mypy](#Mypy)
	- [Code-coverage](#Code-coverage)
		- [Coverage](#Coverage)
	- [Version-management](#Version-management)
		- [pyenv](#pyenv)
	- [Linting](#Linting)
		 - [Ruff](#Ruff)
		 - [Yamllint](#Yamllint)
	 - [Documentation](#Documentation)
		 - [Sphinx](#Sphinx)
- [Logging-and-monitoring](#Logging-and-monitoring)
	 - [Handlers](#Handlers)
		 - [Splunk](#Splunk)
	 - [Azure-log-analytics](#Azure-log-analytics)
- [Automation-Environment-orchestrators](#Automation-Environment-orchestrators)
	 - [Tox](#Tox)
	 - [Pre-commit](#Pre-commit)
	 - [Makefile](#Makefile)
- [ML-ops](#ML-ops)
	- [Mlflow](#Mlflow)
- [Data-platforms](#Data-platforms)
	- [Snowflake](#Snowflake)
	- [Databricks](#Databricks)
- [IAC](#IAC)
	- [Pulumi](#Pulumi)
- [Security-platforms](#Security-platforms)
	- [Snyk](#Snyk)
- [Databases](#Databases)
	- [Postgres](#Postgres)
- [Cross-platform-tools](#Cross-platform-tools)
	- [Dbeaver](#Dbeaver)
	- [Azure-CLI](#Azure-CLI)
	- [Databricks-CLI](#Databricks-CLI)
- [Repository-managers](#Repository-managers)
	- [JFrog-Artifactory](#JFrog-Artifactory)
- [Repository-setup](#Repository-setup)
	- [Azure-DevOps](#Azure-DevOps)
- [Apps](#Apps)
	- [Postman](#Postman)
- [Workflow-automation](#Workflow-automation)
	- [Apache-Airflow](#Apache-Airflow)
- [Package-managers](#Package-managers)
	- [Homebrew](#Homebrew)
	- [pip](#pip)
- [Kubernetes](#Kubernetes)
	- [CLI](#CLI)
	- [Kubelogin](#Kubelogin)
	- [Helm](#Helm)
- [Configuration-manager](#Configuration-manager)
	- [PyHocon](#PyHocon)
- [Streaming](#Streaming)
	- [Kafka](#Kafka)
- [Linux](#Linux)
- [Others](#Others)
	- [Event-hubs](#Event-hubs)
		- [Azure-event-hubs](#Azure-event-hubs)
	- [Code-quality](#Code-quality)
		- [Sonarqube](#Sonarqube)
	- [Code-guides](#Code-guides)
		- [PySpark](#PySpark)
	- [Versioning-and-dependency](#Versioning-and-dependency)
	- [Desmos](#Desmos)
	- [Dask](#Dask)
	- [Dash](#Dash)
- [XAI](#XAI)
	- [SHAP](#SHAP)

# Python

## Unit-testing

### Pytest

- Official Documentation: [https://docs.pytest.org/en/stable/](https://docs.pytest.org/en/stable/).
- Changelog: [https://docs.pytest.org/en/stable/changelog.html](https://docs.pytest.org/en/stable/changelog.html).

## Version-management
### pyenv

pyenv lets you easily switch between multiple versions of Python

- Official documentation : https://github.com/pyenv/pyenv
- Hints : Full installation and setup guide are available in the official documentation page
- Installation  :

```
brew install pyenv

echo 'eval "$(pyenv init --path)"' >> ~/.zprofile
echo 'eval "$(pyenv init -)"' >> ~/.zshrc

# pyenv brew issue https:``//github.com/pyenv/pyenv/issues/106
alias brew=``'env PATH="${PATH//$(pyenv root)\/shims:/}" brew'

```

- Setup :

```
# Download the Python interpreter version you need (you can list available versions with "pyenv install --list"):
pyenv install 3.8.10
pyenv install 3.9.5	

# Make Python versions "global" usable (first in the list is the "default"):
pyenv global 3.8.10 3.9.5
python --version

# Use Python venv module to create virtual environments to separate your project dependencies:
python3.9 -m venv ~/venvs/venv_name

# Use the created venv in your current terminal session:
source ~/venvs/venv_name/bin/activate
python --version

# Upgrade pip and install wheel
python -m pip install --upgrade pip wheel
```

- (Optional) We can do the setup from PyCharm :
	- https://www.jetbrains.com/help/pycharm/configuring-python-interpreter.html#add_new_project_interpreter

- Alternatives : https://www.nijho.lt/post/python-environments/

[[#^Top|TOP]]
## Linting

### Ruff

**Ruff** ensures the code adheres to style guidelines and detects issues like unused imports or inconsistent naming conventions.

- Official Documentation : https://docs.astral.sh/ruff/
- Releases : https://github.com/astral-sh/ruff/releases

### Yamllint

**Yamllint** is a versatile linter tool specifically designed for YAML files. It checks for formatting discrepancies, key-value pair issues, and syntax errors, ensuring that YAML files are both syntactically correct and adhere to best practices.

- **Official Documentation**: [yamllint.readthedocs.io](https://yamllint.readthedocs.io/en/stable/
- **Changelog**: [GitHub Changelog](https://github.com/adrienverge/yamllint/blob/master/CHANGELOG.rst)
## Static-type-checking

### Mypy

**Mype** helps ensure that variables and functions are used correctly by checking type annotations in your code without running it. This is particularly useful in Python, which is dynamically typed, meaning type errors are typically only discovered at runtime.

-  Official Documentation: [Mypy Documentation on Read the Docs](https://mypy.readthedocs.io/en/stable/)
- Changelog: [Mypy Changelog on GitHub](https://github.com/python/mypy/blob/master/CHANGELOG.md)

## Code-coverage

Coverage tracks the execution of Python code, noting which lines have been executed and analyzing the source to determine which lines could have been executed but were not. This information is crucial for assessing the effectiveness of tests.
### Coverage

Coverage is a powerful tool for measuring code coverage in Python programs. It helps developers understand which parts of their code are executed during testing, thereby identifying untested or dead code.
 
- **Official Documentation**: [Coverage.py Documentation](https://coverage.readthedocs.io/)
- **How It Works**: [How Coverage.py Works](https://coverage.readthedocs.io/en/latest/howitworks.html)
- **Installation Instructions**: [Installation Guide](https://coverage.readthedocs.io/en/latest/install.html)
- **Command Line Usage**: [Command Line Documentation](https://coverage.readthedocs.io/en/latest/cmd.html)
- **Change History**: [Release Notes](https://coverage.readthedocs.io/en/latest/changes.html)

## Logging-and-monitoring

## Handlers
### Splunk

- Logging and monitoring solution
- Can be connected to ticketing system or send alerts via email or teams
## Azure-log-analytics

- Azure Monitor Logs : https://learn.microsoft.com/en-us/azure/azure-monitor/logs/data-platform-logs
- Log-analytics workspace : https://learn.microsoft.com/en-us/azure/azure-monitor/logs/log-analytics-workspace-overview
- Kusto query language (KQL) : https://learn.microsoft.com/en-us/kusto/query/tutorials/learn-common-operators?view=azure-data-explorer&preserve-view=true&pivots=azuredataexplorer


[[#^Top|TOP]]
## Documentation 

### Sphinx

- Officia documentation : https://sphinxcontrib-napoleon.readthedocs.io/en/latest/index.html
## Automation-Environment-orchestrators

### Tox

Tox is an environment orchestrator. Use it to define how to setup and execute various tools on your projects.

- Official Documentation: https://tox.wiki/en/latest/installation.html
- Release history : https://tox.wiki/en/latest/changelog.html

### Pre-commit

A framework for managing and maintaining multi-language pre-commit hooks.

- Official documentation : https://pre-commit.com/
- Releases : https://github.com/pre-commit/pre-commit/releases

## Makefile

Makefile is a special file used by the make build automation tool to define how to compile and link a program. It specifies rules, dependencies, and commands required to build a project efficiently.

Makefile consists of : 
- Rules - define how to generate a target
- Dependencies - Specify what files are needed to build the target
- Commands - The shell commands executed ti build the target

Documentation : 
- https://makefiletutorial.com/#why-do-makefiles-exist
- https://opensource.com/article/18/8/what-how-makefile

Hints : 
- In PyCharm we can install Plugins

[[#^Top|TOP]]

# ML-ops
## Mlflow

MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for machine learning projects, ensuring that each phase is manageable, traceable, and reproducible.

Core components :
- Evaluation
- ML Ops
- Tracking
	- managed (e.g. [https://www.databricks.com/product/managed-mlflow](https://www.databricks.com/product/managed-mlflow))
	- self hosted
- Deployment
- Registry

- Officia documentation :
	- Official Documentation : https://mlflow.org/docs/latest/
	- API Docs : https://mlflow.org/docs/latest/api_reference/
- Tutorials : 
	- https://mlflow.org/docs/latest/getting-started/logging-first-model
- Aliases
	- Champion / candidate / archived
[[#^Top|TOP]]

# Data-platforms
## Snowflake

Cloud-based data platform that provides data storage, processing, and analytics solutions. It is a Software-as-a-Service (SaaS) offering that enables businesses to store and analyse large amounts of data efficiently.

- Official page : https://www.snowflake.com/en/emea/
- Documentation : https://docs.snowflake.com/en/user-guide-getting-started
- Releases : https://docs.snowflake.com/en/release-notes/new-features

## Databricks

- Official page : https://www.databricks.com/

[[#^Top|TOP]]

## IAC

### Pulumi

**Infrastructure as Code (IaC)** is an approach to managing and provisioning infrastructure through code rather than manual processes. Pulumi is an open-source platform that enables developers and DevOps teams to manage infrastructure using popular programming languages like Python, JavaScript, TypeScript, Go, and .NET languages. Unlike traditional IaC tools that use domain-specific languages (DSLs), Pulumi leverages general-purpose programming languages, making it easier for developers to integrate infrastructure management into their existing workflows

- Official Documentation: [Pulumi Documentation](https://www.pulumi.com/docs/)
- Changelog [Pulumi GitHub Repository](https://github.com/pulumi/pulumi)
- Use cases : 
	- Databricks job orchestration : 
		- Databricks Provider : https://www.pulumi.com/registry/packages/databricks/
		- Databricks Job Resource : https://www.pulumi.com/registry/packages/databricks/api-docs/job/
		- Pulumi Databricks GitHub repo : https://github.com/pulumi/pulumi-databricks

[[#^Top|TOP]]

# Security-platforms
## Snyk

Secure your proprietary code, open source dependencies, container images, and cloud infrastructure all from a single, unified platform.

- Official page : https://snyk.io/
- Documentation : https://docs.snyk.io/
- Products : https://snyk.io/product/
# Databases

## Postgres

PostgreSQL is a powerful, open source object-relational database system with over 35 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.

- Official documentation : https://www.postgresql.org/

### **Key features :** 
- reliability, robustness, and high performance
- highly concurrent database
### 1. **Advanced Indexing**

- PostgreSQL offers several indexing techniques, such as B-tree, Hash, GiST, SP-GiST, BRIN, and GIN, allowing for efficient querying over large datasets. Custom indexes can be built to optimize specific queries.
- https://www.postgresql.org/docs/current/indexes-types.html

### 2. **Concurrency Control**

- It uses Multi-Version Concurrency Control (MVCC) to handle concurrent data access. This allows multiple users to interact with the database without locking each other out, enhancing read/write speeds and overall performance.
- https://www.postgresql.org/docs/7.1/mvcc.html

### 3. **Partitioning**

- Partitioning refers to splitting what is logically one large table into smaller physical pieces
- https://www.postgresql.org/docs/current/ddl-partitioning.html

### 4. **Parallel Query Execution**

- The database can execute queries in parallel across multiple CPU cores, significantly speeding up data processing and analysis
- https://www.postgresql.org/docs/17/how-parallel-query-works.html

### PostgreSQL and Asynchronous Programming in Python

Python’s asynchronous capabilities, enabled through libraries like `asyncio`, are well-matched with PostgreSQL's features for a number of reasons:

### 1. **Asynchronous Support**

- Libraries such as `asyncpg` are specifically designed for asynchronous operation with PostgreSQL. `asyncpg` is a Python library that provides a high-performance database interface specifically tailored for asyncio.
- https://github.com/MagicStack/asyncpg
### 2. **High Throughput**

- `asyncpg` is one of the fastest database drivers available for PostgreSQL and Python, capable of performing tens of thousands of database transactions per second per core, making full use of PostgreSQL's capabilities without blocking Python’s async loop.

### 3. **Scalability**

- Asynchronous programming combined with PostgreSQL’s inherent scalability features like connection pooling (via tools like `pgBouncer` or `asyncpg`'s pool) enables Python applications to handle large volumes of data and user connections efficiently.
- https://www.pgbouncer.org/

[[#^Top|TOP]]

# Cross-platform-tools
## Dbeaver

DBeaver Community is a free cross-platform database tool for developers, database administrators, analysts, and everyone working with data. It supports all popular SQL databases like MySQL, MariaDB, PostgreSQL, SQLite, Apache Family, and more.

- Official documentation : https://dbeaver.io/

[[#^Top|TOP]]
## Azure-CLI

The Azure Command-Line Interface (CLI) is a cross-platform command-line tool that can be installed locally on macOS computers. You can use the Azure CLI to connect to Azure and execute administrative commands on Azure resources using interactive command-line prompts or a script.

- Install Azure-CLI : https://learn.microsoft.com/en-us/cli/azure/install-azure-cli-macos

```
brew install azure-cli
az login

```

[[#^Top|TOP]]
## Databricks-CLI

- Install Databricks CLI : https://docs.databricks.com/aws/en/dev-tools/cli/install
- Databricks CLI Information : https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/cli/

[[#^Top|TOP]]
# Repository-managers

## JFrog-Artifactory

JFrog Artifactory is a **universal binary repository manager** that enables teams to store, manage, and organize software packages throughout the development lifecycle.

- Official page : https://jfrog.com/artifactory/
- Information : https://codefresh.io/learn/jfrog-artifactory/#:~:text=JFrog%20Artifactory%20is%20a%20universal,packages%20throughout%20the%20development%20lifecycle.

[[#^Top|TOP]]

## Repository-setup
### Azure-DevOps

- Create and target environments :  https://learn.microsoft.com/en-us/azure/devops/pipelines/process/environments?view=azure-devops
- YAML pipeline editor : https://learn.microsoft.com/en-us/azure/devops/pipelines/get-started/yaml-pipeline-editor?view=azure-devops
- YAML schema reference : https://learn.microsoft.com/en-us/azure/devops/pipelines/yaml-schema/?view=azure-pipelines&viewFallbackFrom=azure-devops&tabs=schema%2Cparameter-schema#pool
- Pre-defined variables : https://learn.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&tabs=yaml

# Apps
## Postman

Postman is an API platform for building and using APIs

- Product page : https://www.postman.com/

Can be used for :

- API testing
- API management

[[#^Top|TOP]]

# Workflow-automation
## Apache-Airflow

Open source tool to manage data pipelines

- Documentation : https://airflow.apache.org/
- Alternatives : https://neptune.ai/blog/best-workflow-and-pipeline-orchestration-tools

Tags :
#ml, #workflows, #pipeline-orchestration, #neptune-ai

[[#^Top|TOP]]

# Package-managers
## Homebrew

- Official documentation : https://brew.sh/
- Hints : 
	- Install homebrew 
		- `/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"`
	- Installing Homebrew also installs the Xcode Command Line Tools which include git.

## pip
- Official documentation : https://pip.pypa.io/en/stable/cli/pip_install/

[[#^Top|TOP]]

# Kubernetes

Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation.

- Kubernetes basics : https://kubernetes.io/docs/tutorials/kubernetes-basics/
## CLI : 
- https://kubernetes.io/docs/reference/kubectl/quick-reference/
## Kubelogin :
- https://github.com/Azure/kubelogin
## Helm
- https://helm.sh/docs/intro/install/

- Steps to set up : 

```
# Login to Azure
az login

```
[[#^Top|TOP]]

# Configuration-manager
## PyHocon

HOCON parser for Python

- Official documentation : https://github.com/chimpler/pyhocon

[[#^Top|TOP]]

# Streaming
## Kafka

- Azure docs for Kafka streaming in Databricks : https://learn.microsoft.com/en-us/azure/databricks/connect/streaming/kafka#python

# Linux

- Command documentation : https://www.gnu.org/software/grep/manual/html_node/Index.html
- Bash script mode : https://gist.github.com/mohanpedala/1e2ff5661761d3abd0385e8223e16425
# Others

## Event-hubs
### Azure-event-hubs

- Official https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-about

[[#^Top|TOP]]

## Sonarqube

[SonarQube](https://www.sonarsource.com/products/sonarqube/ "SonarQube") is a self-managed, automatic code review tool that systematically helps you deliver Clean Code.

- Official documentation : https://docs.sonarsource.com/sonarqube-server/10.4/
- Rules : https://rules.sonarsource.com/python/

[[#^Top|TOP]]

## Code-guides
### PySpark

- https://github.com/palantir/pyspark-style-guide

[[#^Top|TOP]]
### Python-coding-style

- Google : http://google.github.io/styleguide/pyguide.html
	- Exceptions : 
		- Using other linters (SonarQube, SonarLint)
		- Line length : 120

[[#^Top|TOP]]
### Versioning-and-dependency

- Official documentation : https://peps.python.org/pep-0440/
	- The versioning scheme follows: _major.minor.patch-[opt-build]_
	- Semantic Versioning 2.0.0 : https://semver.org/

[[#^Top|TOP]]
# Desmos

_Desmos_ Studio offers free graphing, scientific, 3d, and geometry calculators used globally

- Official site : https://www.desmos.com/

[[#^Top|TOP]]
# Dask

- Python library for parallel and distributed computing
- Official documentation : https://docs.dask.org/en/stable/

[[#^Top|TOP]]

# Dash

Plotly Dash Enterprise is the leading data app platform for data scientists and domain experts to create production-grade, interactive data applications in Python, assisted by AI.

- Official site : https://plotly.com/dash/
- Dash gallery :  https://dash.gallery/Portal/

[[#^Top|TOP]]

# XAI

## Shap

- Official documentation : https://shap.readthedocs.io/en/latest/index.html
- Release notes : https://shap.readthedocs.io/en/latest/release_notes.html

#XAI, #SHAP

[[#^Top|TOP]]
### Useful 

- Using Git source control in VS Code : https://code.visualstudio.com/docs/sourcecontrol/overview
- Azure Storage Explorer : https://azure.microsoft.com/en-us/products/storage/storage-explorer/
- An extremely fast Python package and project manager, written in Rust : https://docs.astral.sh/uv/
- Profiling tools : https://medium.com/@narenandu/profiling-and-visualization-tools-in-python-89a46f578989
- Distributed LGBM : https://docs.ray.io/en/latest/train/examples/lightgbm/lightgbm_example.html
- Mlflow : https://dzlab.github.io/ml/2020/07/12/ml-ci-mlflow/
- Guides :
	- https://towardsdatascience.com/regression-for-imbalanced-data-with-application-edf93517247c/
	- GPU TreeShap : https://arxiv.org/abs/2010.13972
	- https://christophm.github.io/interpretable-ml-book/feature-importance.html
- Other tools
	- Proxifier
	- Jet brains
	- Data Expectations
		- SODA (not tested)
			- https://docs.soda.io/soda/connect-spark.html
		- Great Expectations
			- https://docs.greatexpectations.io/docs/core/set_up_a_gx_environment/create_a_data_context/
	- Reguliarization in NN
		- https://www.pinecone.io/learn/regularization-in-neural-networks/#:~:text=Regularization%20techniques%20help%20improve%20a,network%20to%20more%20diverse%20data.
	- Concurency vs parallelelizm
		- https://medium.com/@itIsMadhavan/concurrency-vs-parallelism-a-brief-review-b337c8dac350
	- SHAP
		- https://www.yourdatateacher.com/2021/05/17/how-to-explain-neural-networks-using-shap/
	- what-if analysis
		- https://docs.aws.amazon.com/forecast/latest/dg/what-if.html
	- KPIs
		- https://demand-planning.com/2020/06/01/8-kpis-every-demand-planner-should-know/
	- Polars
		- https://medium.com/mlearning-ai/polars-a-superior-choice-to-pandas-1ab310f8de52
	- Chainlit
		- https://docs.chainlit.io/get-started/pure-python
	- Neural Network in Excel, example :
		- https://www.mynextemployee.com/post/neural-network-in-excel-example
		- https://www.youtube.com/watch?v=aircAruvnKk
		- https://medium.com/technology-invention-and-more/how-to-build-a-simple-neural-network-in-9-lines-of-python-code-cc8f23647ca1#.l51z38s7f
	- Dynamic pricing :
		- https://medium.com/@beyilmaz/list/dynamic-pricing-230859fa4ea6
		- https://tryolabs.com/blog/2019/05/14/can-you-beat-this-pricing-algorithm#what-the-game-is-not-about
		- https://tryolabs.com/blog/price-optimization-machine-learning
		- https://tryolabs.com/blog/2021/04/19/reinforcement-learning--pricing-a-complicated-love-story
		- https://ewrl.wordpress.com/wp-content/uploads/2015/02/ewrl12_2015_submission_23.pdf
		- https://github.com/jwmueller/BanditDynamicPricing/tree/master
		- https://www.analyticsvidhya.com/blog/2018/09/reinforcement-multi-armed-bandit-scratch-python/
		- https://datascience.oneoffcoder.com/pricing-elasticity-basics.html
		- https://datascience.oneoffcoder.com/fitting-demand-curves.html
		- https://towardsdatascience.com/dynamic-pricing-with-reinforcement-learning-from-scratch-q-learning-fb3fb764da49/#f694
		- https://github.com/amitvkulkarni/Data-Apps/tree/main/Price%20Optimization
		- https://jadhavpritish.github.io/Leveraging%20Explore%20Exploit%20strategy%20for%20determining%20the%20optimal%20price%20for%20a%20product..html
		- https://induraj2020.medium.com/implementing-dynamic-pricing-strategy-in-python-part-2-e87e72cd01c9
		- https://medium.com/@baabak/dynamic-pricing-using-machine-learning-5e882282effe
	- Contextual-bandits
		- https://contextual-bandits.readthedocs.io/en/latest/
	- A/A test
		- https://blog.twitch.tv/en/2021/11/04/simulated-bootstrapped-aa-tests-1/
	- Track marketing spendings : 
		- https://medium.com/trusted-data-science-haleon/using-reinforcement-learning-to-track-marketing-spend-db67e843476b
[[#^Top|TOP]]
