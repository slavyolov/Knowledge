**Reading list :**
- [The Multi-Armed Bandit Problem and Its Solutions | Lil'Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2018-01-23-multi-armed-bandit/)
- [Guide to Multi-Arm Bandits: What is it, and why you probably shouldnâ€™t use it. | by Graham McNicoll | GrowthBook | Medium](https://medium.com/growth-book/guide-to-multi-arm-bandits-what-is-it-and-why-you-probably-shouldnt-use-it-ecc9bb2e5a84)

**Code :**

**Question marks | open points :** 
- If the reward for every potential action is known why we need RL (MAB specifically) ?  
	- ANSWER : If the reward for every potential action is known, then why do you need multi-armed bandits? The optimal policy becomes trivial, just pick the best action.  
	  - https://stats.stackexchange.com/a/108786