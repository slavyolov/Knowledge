

**Links :**
- A Gentle Introduction to Information Entropy : https://machinelearningmastery.com/what-is-information-entropy/
- Information Gain and Mutual Information for Machine Learning : https://machinelearningmastery.com/information-gain-and-mutual-information/
- A Simple Explanation of Information Gain and Entropy : https://victorzhou.com/blog/information-gain/

**Takeaways :** 

A Simple Explanation of Information Gain and Entropy : https://victorzhou.com/blog/information-gain/
	- used to train Decision Trees
	- measure the **quality of a split**.
	- **Information Entropy**
		- In the context of training Decision Trees, Entropy can be roughly thought of as **how much variance the data has**
			- A dataset of only one class (blue balls)  would have very **low** (in fact, zero) entropy.
			- A dataset of mixed blues, greens, and reds  would have relatively **high** entropy.
			- ![[Pasted image 20230107121106.png]]
	- **Information Gain**
		- 
- Tags :
		- #InformationEntropy, #InformationGain


- https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/#:~:text=Null%20Error%20Rate%3A%20This%20is,to%20compare%20your%20classifier%20against.